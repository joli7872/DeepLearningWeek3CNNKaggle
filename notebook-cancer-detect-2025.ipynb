{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"},{"sourceId":497805,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":395517,"modelId":414077}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-30T03:51:56.069642Z","iopub.execute_input":"2025-07-30T03:51:56.069891Z","iopub.status.idle":"2025-07-30T03:51:56.342127Z","shell.execute_reply.started":"2025-07-30T03:51:56.069872Z","shell.execute_reply":"2025-07-30T03:51:56.341231Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Deliverable 1 — A Jupyter notebook with a description of the problem/data, exploratory data analysis (EDA) procedure, analysis (model building and training), result, and discussion/conclusion. \n\nSuppose your work becomes so large that it doesn’t fit into one notebook (or you think it will be less readable by having one large notebook). In that case, you can make several notebooks or scripts in a GitHub repository (as deliverable 3) and submit a report-style notebook or pdf instead. \n\nIf your project doesn’t fit into Jupyter notebook format (E.g., you built an app that uses ML), write your approach as a report and submit it in a pdf form. \n\nDeliverable 2 — A public project GitHub repository with your work (please also include the GitHub repo URL in your notebook/report).\n\nDeliverable 3 — A screenshot of your position on the Kaggle competition leaderboard for your top-performing model.\n\nStep 1.\nBrief Description of the problem and ddata\nBrief description of the problem and data (5 pts) \n\nBriefly describe the challenge problem and NLP. Describe the size, dimension, structure, etc., of the data. \n\nStep 2.\nExploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data (15 pts)\n\nShow a few visualizations like histograms. Describe any data cleaning procedures. Based on your EDA, what is your plan of analysis? \n\nStep 3.\nModel Architecture\nDescribe your model architecture and reasoning for why you believe that specific architecture would be suitable for this problem. Compare multiple architectures and tune hyperparameters. \n\nStep 4.\nResults and Analysis (35 pts) \n\nRun hyperparameter tuning, try different architectures for comparison, apply techniques to improve training or performance, and discuss what helped.\n\nIncludes results with tables and figures. There is an analysis of why or why not something worked well, troubleshooting, and a hyperparameter optimization procedure summary.\n\nStep 5. \nConclusion (15 pts)\n\nDiscuss and interpret results as well as learnings and takeaways. What did and did not help improve the performance of your models? What improvements could you try in the future?\n\nStep 6.\nProduce Deliverables: High-Quality, Organized Jupyter Notebook Report, GitHub Repository, and screenshot of Kaggle leaderboard (35 points)\n\nThese deliverables serve two purposes- grade for this course and your project portfolio that you can show when you apply for jobs.\n\nIf you haven’t used GitHub previously, please find a tutorial and get acquainted with it before the project deadline. For the sake of this project, you can use GitHub to showcase your codebase. In the real world, versioning with GitHub is vital for collaboration. Sometimes Jupyter notebooks don’t seem particularly well-suited to versioning with GitHub due to hard-to-read diffs and the like. If you want to use this project as an opportunity to practice versioning with GitHub, consider something like the following: ","metadata":{}},{"cell_type":"markdown","source":"**Part 1: Brief Description of the Problem and Data**\nThis project uses the kaggle competition dataset https://www.kaggle.com/competitions/histopathologic-cancer-detection/overview. The goal is to use convolutional neural networks (CNN) to identify metastatic cancer in small image patches. The data are RBG images, and the image files are .tif files. The images are of cells that will be labeled cancer or not having cancer, and our job is to perform image classification to predict the labels of the test images.","metadata":{}},{"cell_type":"markdown","source":"**Part 2. Exploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data**\n\nLoad the libraries\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimport time\n\nimport cv2 # For EDA\n\nfrom PIL import Image\n\nimport sys\n\nfrom numpy.random import seed\nseed(101)\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport shutil\ntf.random.set_seed(101)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T03:52:01.256946Z","iopub.execute_input":"2025-07-30T03:52:01.257790Z","iopub.status.idle":"2025-07-30T03:52:15.324731Z","shell.execute_reply.started":"2025-07-30T03:52:01.257766Z","shell.execute_reply":"2025-07-30T03:52:15.324005Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load Data","metadata":{}},{"cell_type":"code","source":"train_labels_df = pd.read_csv('/kaggle/input/histopathologic-cancer-detection/train_labels.csv')\ntrain_labels_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T03:52:21.843844Z","iopub.execute_input":"2025-07-30T03:52:21.844449Z","iopub.status.idle":"2025-07-30T03:52:22.251200Z","shell.execute_reply.started":"2025-07-30T03:52:21.844422Z","shell.execute_reply":"2025-07-30T03:52:22.250425Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Check for duplicate entries","metadata":{}},{"cell_type":"code","source":"train_labels_df[train_labels_df.duplicated(keep=False)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T03:52:24.350773Z","iopub.execute_input":"2025-07-30T03:52:24.351095Z","iopub.status.idle":"2025-07-30T03:52:24.450343Z","shell.execute_reply.started":"2025-07-30T03:52:24.351073Z","shell.execute_reply":"2025-07-30T03:52:24.449473Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"No duplicated were found","metadata":{}},{"cell_type":"markdown","source":"We will take a look at the distribution of data (cancer vs non-cancerous)","metadata":{}},{"cell_type":"code","source":"train_labels_df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T01:39:53.281986Z","iopub.execute_input":"2025-07-29T01:39:53.282231Z","iopub.status.idle":"2025-07-29T01:39:53.289774Z","shell.execute_reply.started":"2025-07-29T01:39:53.282217Z","shell.execute_reply":"2025-07-29T01:39:53.289143Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"The dataset favors non-cancer (0), vs cancer (1) and not too skewed in terms of distribution\nLet's take a look at the images and see if there is anything that pops out at us. I highly doubt a visual inspection will help us, as cancer detection is extremely hard to an untrained eye.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(25, 8))\ntrain_imgs = os.listdir(\"/kaggle/input/histopathologic-cancer-detection/train\")\nfor idx, img in enumerate(np.random.choice(train_imgs, 40)):\n    ax = fig.add_subplot(4, 10, idx+1, xticks=[], yticks=[])\n    im = Image.open(\"/kaggle/input/histopathologic-cancer-detection/train/\" + img)\n    plt.imshow(im)\n    lab = train_labels_df.loc[train_labels_df['id'] == img.split('.')[0], 'label'].values[0]\n    ax.set_title(f'Label: {lab}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T01:52:04.371689Z","iopub.execute_input":"2025-07-29T01:52:04.371907Z","iopub.status.idle":"2025-07-29T01:52:09.297575Z","shell.execute_reply.started":"2025-07-29T01:52:04.371894Z","shell.execute_reply":"2025-07-29T01:52:09.296873Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As expected, there is nothing that is obvious for identifying the cancer.....\nBased on our EDA, we found no duplicates an extremely large number of images (220025 for training), and relatively even distribution of classification.\nFor the analysis and model creation, I plan to lower the sample size drastically for performance purposes so we can do our analysis faster.","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE=96\nIMAGE_CHANNELS=3\nSAMPLE_SIZE=2000  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T03:52:33.589979Z","iopub.execute_input":"2025-07-30T03:52:33.590268Z","iopub.status.idle":"2025-07-30T03:52:33.594104Z","shell.execute_reply.started":"2025-07-30T03:52:33.590247Z","shell.execute_reply":"2025-07-30T03:52:33.593328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''df0=train_labels_df[train_labels_df['label']==0].sample(SAMPLE_SIZE,random_state=101)\ndf1=train_labels_df[train_labels_df['label']==1].sample(SAMPLE_SIZE,random_state=101)\ndf_data = pd.concat([df0, df1], axis=0) #.reset_index(drop=True)\ndf_data = shuffle(df_data)\ny = df_data['label']\ndf_train, df_val = train_test_split(df_data, test_size=0.20, random_state=101, stratify=y)\nprint(df_train.shape)\nprint(df_val.shape)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T02:46:47.725283Z","iopub.execute_input":"2025-07-29T02:46:47.725580Z","iopub.status.idle":"2025-07-29T02:46:47.748371Z","shell.execute_reply.started":"2025-07-29T02:46:47.725564Z","shell.execute_reply":"2025-07-29T02:46:47.747554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''base_dir='base_dir'\nos.mkdir(base_dir)\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\nno_cancer = os.path.join(train_dir, 'no_cancer')\nos.mkdir(no_cancer)\nyes_cancer = os.path.join(train_dir, 'yes_cancer')\nos.mkdir(yes_cancer)\nno_cancer = os.path.join(val_dir, 'no_cancer')\nos.mkdir(no_cancer)\nyes_cancer = os.path.join(val_dir, 'yes_cancer')\nos.mkdir(yes_cancer)\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T02:46:50.790422Z","iopub.execute_input":"2025-07-29T02:46:50.790677Z","iopub.status.idle":"2025-07-29T02:46:50.803495Z","shell.execute_reply.started":"2025-07-29T02:46:50.790663Z","shell.execute_reply":"2025-07-29T02:46:50.802529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''os.listdir('base_dir/train_dir')'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T02:45:24.334110Z","iopub.execute_input":"2025-07-29T02:45:24.334370Z","iopub.status.idle":"2025-07-29T02:45:24.339770Z","shell.execute_reply.started":"2025-07-29T02:45:24.334354Z","shell.execute_reply":"2025-07-29T02:45:24.338589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''df_data.head()'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T02:46:56.029125Z","iopub.execute_input":"2025-07-29T02:46:56.029375Z","iopub.status.idle":"2025-07-29T02:46:56.036092Z","shell.execute_reply.started":"2025-07-29T02:46:56.029359Z","shell.execute_reply":"2025-07-29T02:46:56.035201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''df_data.set_index('id', inplace=True)\ntrain_list = list(df_train['id'])\nval_list = list(df_val['id'])\nfor image in train_list:\n    \n    # the id in the csv file does not have the .tif extension therefore we add it here\n    fname = image + '.tif'\n    # get the label for a certain image\n    target = df_data.loc[image,'label']\n    \n    # these must match the folder names\n    if target == 0:\n        label = 'no_cancer'\n    if target == 1:\n        label = 'yes_cancer'\n    \n    # source path to image\n    src = os.path.join('/kaggle/input/histopathologic-cancer-detection/train', fname)\n    # destination path to image\n    dst = os.path.join(train_dir, label, fname)\n    # copy the image from the source to the destination\n    shutil.copyfile(src, dst)\n\n\n# Transfer the val images\n\nfor image in val_list:\n    \n    # the id in the csv file does not have the .tif extension therefore we add it here\n    fname = image + '.tif'\n    # get the label for a certain image\n    target = df_data.loc[image,'label']\n    \n    # these must match the folder names\n    if target == 0:\n        label = 'no_cancer'\n    if target == 1:\n        label = 'yes_cancer'\n    \n\n    # source path to image\n    src = os.path.join('/kaggle/input/histopathologic-cancer-detection/train', fname)\n    # destination path to image\n    dst = os.path.join(val_dir, label, fname)\n    # copy the image from the source to the destination\n    shutil.copyfile(src, dst)\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T02:46:57.873994Z","iopub.execute_input":"2025-07-29T02:46:57.874222Z","iopub.status.idle":"2025-07-29T02:47:02.827687Z","shell.execute_reply.started":"2025-07-29T02:46:57.874208Z","shell.execute_reply":"2025-07-29T02:47:02.827058Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Set up the Generators","metadata":{}},{"cell_type":"code","source":"'''train_path = 'base_dir/train_dir'\nvalid_path = 'base_dir/val_dir'\ntest_path = '/kaggle/input/histopathologic-cancer-detection/test'\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 10\nval_batch_size = 10\n\n\ntrain_steps = np.ceil(num_train_samples / train_batch_size)\nval_steps = np.ceil(num_val_samples / val_batch_size)\ndatagen = ImageDataGenerator(rescale=1.0/255)\n\ntrain_gen = datagen.flow_from_directory(train_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=train_batch_size,\n                                        class_mode='categorical')\n\nval_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=val_batch_size,\n                                        class_mode='categorical')\n\n# Note: shuffle=False causes the test dataset to not be shuffled\ntest_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=1,\n                                        class_mode='categorical',\n                                        shuffle=False)\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T02:47:04.473586Z","iopub.execute_input":"2025-07-29T02:47:04.473835Z","iopub.status.idle":"2025-07-29T02:47:04.567962Z","shell.execute_reply.started":"2025-07-29T02:47:04.473820Z","shell.execute_reply":"2025-07-29T02:47:04.567324Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"'''kernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.3\n\n\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(2, activation = \"softmax\"))\n\nmodel.summary()'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T02:47:08.983655Z","iopub.execute_input":"2025-07-29T02:47:08.983896Z","iopub.status.idle":"2025-07-29T02:47:09.156271Z","shell.execute_reply.started":"2025-07-29T02:47:08.983883Z","shell.execute_reply":"2025-07-29T02:47:09.155389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''model.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', \n              metrics=['accuracy'])\nprint(val_gen.class_indices)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T02:47:14.940614Z","iopub.execute_input":"2025-07-29T02:47:14.940868Z","iopub.status.idle":"2025-07-29T02:47:14.949868Z","shell.execute_reply.started":"2025-07-29T02:47:14.940851Z","shell.execute_reply":"2025-07-29T02:47:14.949036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''filepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n                              \n                              \ncallbacks_list = [checkpoint, reduce_lr]\n\nhistory = model.fit(train_gen, \n                    validation_data=val_gen,\n                    epochs=20, verbose=1,\n                   callbacks=callbacks_list)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T02:48:11.911626Z","iopub.execute_input":"2025-07-29T02:48:11.911900Z","iopub.status.idle":"2025-07-29T03:15:05.306247Z","shell.execute_reply.started":"2025-07-29T02:48:11.911884Z","shell.execute_reply":"2025-07-29T03:15:05.305697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''model.metrics_names'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T03:17:16.729572Z","iopub.execute_input":"2025-07-29T03:17:16.731203Z","iopub.status.idle":"2025-07-29T03:17:16.744838Z","shell.execute_reply.started":"2025-07-29T03:17:16.731120Z","shell.execute_reply":"2025-07-29T03:17:16.744130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''val_loss, val_acc = model.evaluate(test_gen, \n                        steps=len(df_val))\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T03:17:37.226700Z","iopub.execute_input":"2025-07-29T03:17:37.227209Z","iopub.status.idle":"2025-07-29T03:17:44.422193Z","shell.execute_reply.started":"2025-07-29T03:17:37.227178Z","shell.execute_reply":"2025-07-29T03:17:44.421537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T03:17:57.482033Z","iopub.execute_input":"2025-07-29T03:17:57.482679Z","iopub.status.idle":"2025-07-29T03:17:57.840321Z","shell.execute_reply.started":"2025-07-29T03:17:57.482660Z","shell.execute_reply":"2025-07-29T03:17:57.839699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''test_gen.class_indices'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T03:19:26.921145Z","iopub.execute_input":"2025-07-29T03:19:26.921422Z","iopub.status.idle":"2025-07-29T03:19:26.926981Z","shell.execute_reply.started":"2025-07-29T03:19:26.921406Z","shell.execute_reply":"2025-07-29T03:19:26.925451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''predictions = model.predict(test_gen, steps=len(df_val), verbose=1)'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T03:20:47.443310Z","iopub.execute_input":"2025-07-29T03:20:47.443581Z","iopub.status.idle":"2025-07-29T03:20:54.693847Z","shell.execute_reply.started":"2025-07-29T03:20:47.443564Z","shell.execute_reply":"2025-07-29T03:20:54.692883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''predictions.shape'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T03:21:01.064428Z","iopub.execute_input":"2025-07-29T03:21:01.064692Z","iopub.status.idle":"2025-07-29T03:21:01.069264Z","shell.execute_reply.started":"2025-07-29T03:21:01.064677Z","shell.execute_reply":"2025-07-29T03:21:01.068620Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''df_preds = pd.DataFrame(predictions, columns=['no_cancer', 'yes_cancer'])\n\ndf_preds.head()'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T03:21:04.073792Z","iopub.execute_input":"2025-07-29T03:21:04.074041Z","iopub.status.idle":"2025-07-29T03:21:04.080999Z","shell.execute_reply.started":"2025-07-29T03:21:04.074025Z","shell.execute_reply":"2025-07-29T03:21:04.080315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''y_true = test_gen.classes\n\ny_pred = df_preds['yes_cancer']\nfrom sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_true, y_pred)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T03:21:47.009591Z","iopub.execute_input":"2025-07-29T03:21:47.009833Z","iopub.status.idle":"2025-07-29T03:21:47.027732Z","shell.execute_reply.started":"2025-07-29T03:21:47.009818Z","shell.execute_reply":"2025-07-29T03:21:47.026970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"It looks like we have a good model for just using a small portion of the training data.\nWe will clear the directories and train the model with the larger dataset.\nWe can also tune the hyperparameters with the larger dataset and find the optimal values.","metadata":{}},{"cell_type":"code","source":"'''shutil.rmtree('base_dir')'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T22:55:45.558166Z","iopub.execute_input":"2025-07-29T22:55:45.558437Z","iopub.status.idle":"2025-07-29T22:55:45.674436Z","shell.execute_reply.started":"2025-07-29T22:55:45.558419Z","shell.execute_reply":"2025-07-29T22:55:45.673497Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Below is all just setting up the training and test data with folders. Same as before.","metadata":{}},{"cell_type":"code","source":"'''SAMPLE_SIZE=10000\ndf_data = pd.read_csv('/kaggle/input/histopathologic-cancer-detection/train_labels.csv')\ndf0=df_data[df_data['label']==0].sample(SAMPLE_SIZE,random_state=42)\ndf1=df_data[df_data['label']==1].sample(SAMPLE_SIZE,random_state=42)\ndf_data = pd.concat([df0, df1], axis=0).reset_index(drop=True)\ndf_data = shuffle(df_data)\ny = df_data['label']\ndf_train, df_val = train_test_split(df_data, test_size=0.20, random_state=42, stratify=y)\nbase_dir='base_dir'\nos.mkdir(base_dir)\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\nno_cancer = os.path.join(train_dir, 'no_cancer')\nos.mkdir(no_cancer)\nyes_cancer = os.path.join(train_dir, 'yes_cancer')\nos.mkdir(yes_cancer)\nno_cancer = os.path.join(val_dir, 'no_cancer')\nos.mkdir(no_cancer)\nyes_cancer = os.path.join(val_dir, 'yes_cancer')\nos.mkdir(yes_cancer)\ndf_data.set_index('id', inplace=True)\ntrain_list = list(df_train['id'])\nval_list = list(df_val['id'])\nfor image in train_list:\n    fname = image + '.tif'\n    target = df_data.loc[image,'label']\n    if target == 0:\n        label = 'no_cancer'\n    if target == 1:\n        label = 'yes_cancer'\n    \n    src = os.path.join('/kaggle/input/histopathologic-cancer-detection/train', fname)\n    dst = os.path.join(train_dir, label, fname)\n    shutil.copyfile(src, dst)\n\nfor image in val_list:\n    \n    fname = image + '.tif'\n    target = df_data.loc[image,'label']\n    \n    if target == 0:\n        label = 'no_cancer'\n    if target == 1:\n        label = 'yes_cancer'\n\n    src = os.path.join('/kaggle/input/histopathologic-cancer-detection/train', fname)\n    dst = os.path.join(val_dir, label, fname)\n    shutil.copyfile(src, dst)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:16:42.226548Z","iopub.execute_input":"2025-07-29T23:16:42.227384Z","iopub.status.idle":"2025-07-29T23:17:03.955517Z","shell.execute_reply.started":"2025-07-29T23:16:42.227350Z","shell.execute_reply":"2025-07-29T23:17:03.954897Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This took about 10 minutes using a Kaggle GPU.\nNow, we set up the model.","metadata":{}},{"cell_type":"code","source":"'''# Set up the generators\ntrain_path = 'base_dir/train_dir'\nvalid_path = 'base_dir/val_dir'\ntest_path = '/kaggle/input/histopathologic-cancer-detection/test'\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 10\nval_batch_size = 10\n\n\ntrain_steps = np.ceil(num_train_samples / train_batch_size)\nval_steps = np.ceil(num_val_samples / val_batch_size)\ndatagen = ImageDataGenerator(rescale=1.0/255)\n\ntrain_gen = datagen.flow_from_directory(train_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=train_batch_size,\n                                        class_mode='categorical')\n\nval_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=val_batch_size,\n                                        class_mode='categorical')\n\n# Note: shuffle=False causes the test dataset to not be shuffled\ntest_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=1,\n                                        class_mode='categorical',\n                                        shuffle=False)\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.3\n\n\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(2, activation = \"softmax\"))\n\nmodel.summary()\n'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:21:45.370922Z","iopub.execute_input":"2025-07-29T23:21:45.371579Z","iopub.status.idle":"2025-07-29T23:21:46.299769Z","shell.execute_reply.started":"2025-07-29T23:21:45.371552Z","shell.execute_reply":"2025-07-29T23:21:46.299051Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"HyperParameter tuning: Vary the learning rate and find the best model.","metadata":{}},{"cell_type":"code","source":"'''learning_rates=[0.0001, 0.001, 0.01]\n\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n                              \n                              \ncallbacks_list = [checkpoint, reduce_lr]\n\n\ncurr_best_model = (None, 0)\ncurr_best_history = None\nfor lr_iter in learning_rates:\n    model.compile(Adam(learning_rate=lr_iter), loss='binary_crossentropy', \n              metrics=['accuracy'])\n    this_history = model.fit(train_gen,\n                    validation_data=val_gen,\n                    epochs=20, verbose=1,\n                   callbacks=callbacks_list)\n    if this_history.history[\"accuracy\"][-1] > curr_best_model[1]:\n        curr_best_model = (model, this_history.history[\"accuracy\"][-1])\n        curr_best_history = this_history.history'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:22:42.118054Z","iopub.execute_input":"2025-07-29T23:22:42.118814Z","iopub.status.idle":"2025-07-29T23:39:32.303086Z","shell.execute_reply.started":"2025-07-29T23:22:42.118787Z","shell.execute_reply":"2025-07-29T23:39:32.302367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Using the GPU on kaggle is about 20x faster than using CPU.\nLet's look at the trained model","metadata":{}},{"cell_type":"markdown","source":"<h1>Part 4: Results and Analysis</h1>\nWe trained the model and tuned learning rate hyperparameter. We optimized for validation accuracy to find the optimal parameters.","metadata":{}},{"cell_type":"markdown","source":"A learning rate of 0.0001 was found to be optimal.\nSometimes we have to start from here and plug in the learning rate instead of referencing curr_best_model if the connection to kaggle is lost.\nSkip this next step if the model was trained and connection was not lost to kaggle","metadata":{}},{"cell_type":"code","source":"# Set up the generators\nSAMPLE_SIZE=10000\n'''df_data = pd.read_csv('/kaggle/input/histopathologic-cancer-detection/train_labels.csv')\ndf0=df_data[df_data['label']==0].sample(SAMPLE_SIZE,random_state=42)\ndf1=df_data[df_data['label']==1].sample(SAMPLE_SIZE,random_state=42)\ndf_data = pd.concat([df0, df1], axis=0).reset_index(drop=True)\ndf_data = shuffle(df_data)\ny = df_data['label']\ndf_train, df_val = train_test_split(df_data, test_size=0.20, random_state=42, stratify=y)\nbase_dir='base_dir'\nos.mkdir(base_dir)\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\nno_cancer = os.path.join(train_dir, 'no_cancer')\nos.mkdir(no_cancer)\nyes_cancer = os.path.join(train_dir, 'yes_cancer')\nos.mkdir(yes_cancer)\nno_cancer = os.path.join(val_dir, 'no_cancer')\nos.mkdir(no_cancer)\nyes_cancer = os.path.join(val_dir, 'yes_cancer')\nos.mkdir(yes_cancer)\ndf_data.set_index('id', inplace=True)\ntrain_list = list(df_train['id'])\nval_list = list(df_val['id'])\nfor image in train_list:\n    fname = image + '.tif'\n    target = df_data.loc[image,'label']\n    if target == 0:\n        label = 'no_cancer'\n    if target == 1:\n        label = 'yes_cancer'\n    \n    src = os.path.join('/kaggle/input/histopathologic-cancer-detection/train', fname)\n    dst = os.path.join(train_dir, label, fname)\n    shutil.copyfile(src, dst)\n\nfor image in val_list:\n    \n    fname = image + '.tif'\n    target = df_data.loc[image,'label']\n    \n    if target == 0:\n        label = 'no_cancer'\n    if target == 1:\n        label = 'yes_cancer'\n\n    src = os.path.join('/kaggle/input/histopathologic-cancer-detection/train', fname)\n    dst = os.path.join(val_dir, label, fname)\n    shutil.copyfile(src, dst)\n    \ntrain_path = 'base_dir/train_dir'\nvalid_path = 'base_dir/val_dir'\ntest_path = '/kaggle/input/histopathologic-cancer-detection/test'\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 10\nval_batch_size = 10\n\n\ntrain_steps = np.ceil(num_train_samples / train_batch_size)\nval_steps = np.ceil(num_val_samples / val_batch_size)\ndatagen = ImageDataGenerator(rescale=1.0/255)\n\ntrain_gen = datagen.flow_from_directory(train_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=train_batch_size,\n                                        class_mode='categorical')\n\nval_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=val_batch_size,\n                                        class_mode='categorical')\n\n# Note: shuffle=False causes the test dataset to not be shuffled\ntest_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=1,\n                                        class_mode='categorical',\n                                        shuffle=False)\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.3\n\n\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(2, activation = \"softmax\"))\n\n\nmodel.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', \n              metrics=['accuracy'])\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n                              \n                              \ncallbacks_list = [checkpoint, reduce_lr]\n\nhistory = model.fit(train_gen, \n                    validation_data=val_gen,\n                    epochs=20, verbose=1,\n                   callbacks=callbacks_list)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T03:52:47.370036Z","iopub.execute_input":"2025-07-30T03:52:47.370598Z","iopub.status.idle":"2025-07-30T04:00:46.052402Z","shell.execute_reply.started":"2025-07-30T03:52:47.370572Z","shell.execute_reply":"2025-07-30T04:00:46.051770Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's take a look at the results and plot the curves\n","metadata":{}},{"cell_type":"code","source":"#import tensorflow as tf\n#model.save('/kaggle/working/my_model.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:01:01.293395Z","iopub.execute_input":"2025-07-30T04:01:01.293721Z","iopub.status.idle":"2025-07-30T04:01:01.422712Z","shell.execute_reply.started":"2025-07-30T04:01:01.293698Z","shell.execute_reply":"2025-07-30T04:01:01.422084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#val_loss, val_acc = model.evaluate(test_gen, \n #                       steps=len(df_val))\n\n#print('val_loss:', val_loss)\n#print('val_acc:', val_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:01:30.571978Z","iopub.execute_input":"2025-07-30T04:01:30.572662Z","iopub.status.idle":"2025-07-30T04:01:42.965371Z","shell.execute_reply.started":"2025-07-30T04:01:30.572625Z","shell.execute_reply":"2025-07-30T04:01:42.964716Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Display loss and accuracy curves","metadata":{}},{"cell_type":"code","source":"'''acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:01:45.842631Z","iopub.execute_input":"2025-07-30T04:01:45.842937Z","iopub.status.idle":"2025-07-30T04:01:46.379563Z","shell.execute_reply.started":"2025-07-30T04:01:45.842916Z","shell.execute_reply":"2025-07-30T04:01:46.378851Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Make predictions","metadata":{}},{"cell_type":"code","source":"#predictions = model.predict(test_gen, steps=len(df_val), verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T01:28:18.110656Z","iopub.execute_input":"2025-07-30T01:28:18.111052Z","iopub.status.idle":"2025-07-30T01:28:28.620493Z","shell.execute_reply.started":"2025-07-30T01:28:18.111029Z","shell.execute_reply":"2025-07-30T01:28:28.619852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#predictions.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T01:28:34.158483Z","iopub.execute_input":"2025-07-30T01:28:34.159203Z","iopub.status.idle":"2025-07-30T01:28:34.163766Z","shell.execute_reply.started":"2025-07-30T01:28:34.159180Z","shell.execute_reply":"2025-07-30T01:28:34.163105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df_preds = pd.DataFrame(predictions, columns=['no_cancer', 'yes_cancer'])\n\n#df_preds.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T01:29:06.486021Z","iopub.execute_input":"2025-07-30T01:29:06.486636Z","iopub.status.idle":"2025-07-30T01:29:06.494826Z","shell.execute_reply.started":"2025-07-30T01:29:06.486612Z","shell.execute_reply":"2025-07-30T01:29:06.494227Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's take a look at the accuracy of predictions","metadata":{}},{"cell_type":"code","source":"'''from sklearn.metrics import roc_auc_score\ny_true = test_gen.classes\ny_pred = df_preds['yes_cancer']\nroc_auc_score(y_true, y_pred)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T01:54:26.580072Z","iopub.execute_input":"2025-07-30T01:54:26.580566Z","iopub.status.idle":"2025-07-30T01:54:26.588268Z","shell.execute_reply.started":"2025-07-30T01:54:26.580542Z","shell.execute_reply":"2025-07-30T01:54:26.587625Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Set up test directory for predictions and submission","metadata":{}},{"cell_type":"code","source":"#shutil.rmtree('base_dir')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T01:54:32.375441Z","iopub.execute_input":"2025-07-30T01:54:32.375683Z","iopub.status.idle":"2025-07-30T01:54:32.391200Z","shell.execute_reply.started":"2025-07-30T01:54:32.375666Z","shell.execute_reply":"2025-07-30T01:54:32.390232Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Have to get nested directory for keras to work","metadata":{}},{"cell_type":"code","source":"test_dir = 'test_dir'\nos.mkdir(test_dir)\ntest_images = os.path.join(test_dir, 'test_images')\nos.mkdir(test_images)\nos.listdir('test_dir')\n\ntest_list = os.listdir('/kaggle/input/histopathologic-cancer-detection/test')\n\nfor image in test_list:\n    \n    fname = image\n    \n    src = os.path.join('/kaggle/input/histopathologic-cancer-detection/test', fname)\n    dst = os.path.join(test_images, fname)\n    shutil.copyfile(src, dst)\n\nnum_test_images=len(os.listdir('test_dir/test_images'))\nlen(os.listdir('test_dir/test_images'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:02:26.761585Z","iopub.execute_input":"2025-07-30T04:02:26.762345Z","iopub.status.idle":"2025-07-30T04:11:46.222878Z","shell.execute_reply.started":"2025-07-30T04:02:26.762323Z","shell.execute_reply":"2025-07-30T04:11:46.221802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_test_images=len(os.listdir('/kaggle/input/histopathologic-cancer-detection/test'))\nlen(os.listdir('/kaggle/input/histopathologic-cancer-detection/test'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:23:10.076650Z","iopub.execute_input":"2025-07-30T04:23:10.076997Z","iopub.status.idle":"2025-07-30T04:23:10.116271Z","shell.execute_reply.started":"2025-07-30T04:23:10.076972Z","shell.execute_reply":"2025-07-30T04:23:10.115554Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Point to correct directory","metadata":{}},{"cell_type":"code","source":"test_path ='test_dir'\ndatagen = ImageDataGenerator(rescale=1.0/255)\ntest_gen = datagen.flow_from_directory(test_path,\n                                        target_size=(96,96),\n                                        batch_size=1,\n                                        class_mode='categorical',\n                                        shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:23:58.815425Z","iopub.execute_input":"2025-07-30T04:23:58.815721Z","iopub.status.idle":"2025-07-30T04:23:59.556186Z","shell.execute_reply.started":"2025-07-30T04:23:58.815700Z","shell.execute_reply":"2025-07-30T04:23:59.555483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nimport keras\nmodel = keras.models.load_model('/kaggle/input/modelh5/keras/default/1/my_model.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:19:33.255532Z","iopub.execute_input":"2025-07-30T04:19:33.255833Z","iopub.status.idle":"2025-07-30T04:19:33.554737Z","shell.execute_reply.started":"2025-07-30T04:19:33.255814Z","shell.execute_reply":"2025-07-30T04:19:33.554073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = model.predict(test_gen, steps=num_test_images, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:19:36.377550Z","iopub.execute_input":"2025-07-30T04:19:36.377853Z","iopub.status.idle":"2025-07-30T04:22:35.656856Z","shell.execute_reply.started":"2025-07-30T04:19:36.377831Z","shell.execute_reply":"2025-07-30T04:22:35.656153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:23:17.167285Z","iopub.execute_input":"2025-07-30T04:23:17.167597Z","iopub.status.idle":"2025-07-30T04:23:17.173280Z","shell.execute_reply.started":"2025-07-30T04:23:17.167577Z","shell.execute_reply":"2025-07-30T04:23:17.172133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_preds = pd.DataFrame(predictions, columns=['no_cancer', 'yes_cancer'])\ndf_preds.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:25:16.603658Z","iopub.execute_input":"2025-07-30T04:25:16.604404Z","iopub.status.idle":"2025-07-30T04:25:16.612929Z","shell.execute_reply.started":"2025-07-30T04:25:16.604382Z","shell.execute_reply":"2025-07-30T04:25:16.612194Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Set up format for output document. Extract file name without extension or path","metadata":{}},{"cell_type":"code","source":"test_filenames = test_gen.filenames\ndf_preds['file_names'] = test_filenames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:26:54.819623Z","iopub.execute_input":"2025-07-30T04:26:54.819897Z","iopub.status.idle":"2025-07-30T04:26:54.828559Z","shell.execute_reply.started":"2025-07-30T04:26:54.819878Z","shell.execute_reply":"2025-07-30T04:26:54.827666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_id(x):\n    extract_id = x.split('/')[1].split('.')[0]\n    return extract_id\ntest_filenames = test_gen.filenames\nsubmission = pd.DataFrame({'id':df_preds['file_names'].apply(extract_id), \n                           'label':df_preds['yes_cancer'], \n                          }).set_index('id')\nsubmission.head()\nsubmission.to_csv('/kaggle/working/submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T04:26:57.173617Z","iopub.execute_input":"2025-07-30T04:26:57.173925Z","iopub.status.idle":"2025-07-30T04:26:57.361241Z","shell.execute_reply.started":"2025-07-30T04:26:57.173903Z","shell.execute_reply":"2025-07-30T04:26:57.360366Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"References:\nhttps://keras.io/examples/vision/image_classification_from_scratch/\n","metadata":{}}]}